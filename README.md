# Fine-tuning a Small Language Model in the ReAct Framework

🚧 **Project Status:** In Progress 🚧

## 📌 Project Idea
This project explores how to **fine-tune a Small Language Model (SLM)** using **PyTorch** to operate within the **ReAct (Reason + Act) framework**. The goal is to demonstrate how lightweight transformer models can be adapted into **agentic AI systems** that not only generate text but also **reason, take actions, and use external tools**.

### 🔹 Key Features
- Fine-tuning an SLM with **LoRA adapters** in PyTorch for efficient training.
- Implementing the **ReAct loop** (Thought → Action → Observation → Answer).
- Enabling **tool use** such as:
  - Web/document search
  - Calculator for math reasoning
  - Memory retrieval with embeddings
- Evaluation of reasoning quality, success rate, and tool-use efficiency.

---

## 🤝 Contributions
This is an experimental project in progress. Feedback, suggestions, or collaborations are welcome!
