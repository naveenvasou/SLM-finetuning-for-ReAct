# Fine-tuning a Small Language Model in the ReAct Framework

ğŸš§ **Project Status:** In Progress ğŸš§

## ğŸ“Œ Project Idea
This project explores how to **fine-tune a Small Language Model (SLM)** using **PyTorch** to operate within the **ReAct (Reason + Act) framework**. The goal is to demonstrate how lightweight transformer models can be adapted into **agentic AI systems** that not only generate text but also **reason, take actions, and use external tools**.

### ğŸ”¹ Key Features
- Fine-tuning an SLM with **LoRA adapters** in PyTorch for efficient training.
- Implementing the **ReAct loop** (Thought â†’ Action â†’ Observation â†’ Answer).
- Enabling **tool use** such as:
  - Web/document search
  - Calculator for math reasoning
  - Memory retrieval with embeddings
- Evaluation of reasoning quality, success rate, and tool-use efficiency.

---

## ğŸ¤ Contributions
This is an experimental project in progress. Feedback, suggestions, or collaborations are welcome!
